# RepresentationLearningTheory
This repository contains experiments related to learning representations
of real world data and aligning the representations across modalities (such as text, image, audio, ...).

1. The folder SigLIP contains experiments associated to the paper [Global Minimizers of Sigmoid Contrastive Loss](???) by Iliyas Noman, Kiril Bangachev,
Guy Bresler, and Yury Polyanskiy. SigLIP is a method for aligning representations ofmuliple modalities, [devloped by Google DeepMind](https://arxiv.org/pdf/2303.15343) 
which was later further enhanced via the [SigLIP2 method](https://arxiv.org/abs/2502.14786).
